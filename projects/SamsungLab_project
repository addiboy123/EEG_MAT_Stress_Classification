{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9528802,"sourceType":"datasetVersion","datasetId":5802752},{"sourceId":9532363,"sourceType":"datasetVersion","datasetId":5805412}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/samsunglab-project-b22d3121-5673-4dd9-8272-1a51bde633f2.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241009/auto/storage/goog4_request&X-Goog-Date=20241009T175352Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=a6240328d402a2bdc7e648679a663d0f6f152a7e4b2fc2ebeabc6ffa6c305c3aa0f0db76e14791c23ded68bbfdb5c378ee66b19020dd9c6e46386fd3a6473dcdc66a5ee4055b256cac581e52f5551b8d7061788e3e5cc0057fb477eb7cd60f781c1f65f1e99808e7adc27c84ccd25196181c4056c7947e905fee89f48fb347d6fb6a33bbdb8b526ba622c22f5b9760a3ad88e2bbff330205fcef1d3afa09054fbef0f32332bb9c3c524d4aae1ab4254e3da5e8376795dff10a7be03a0a643d792d6cf3717b8413f63b5ac1b4abcd369be28dae6ca8145bdef2bc7854571396fb95b6bef36b226cc68c9f32107220026a9ba64abeb9469fccbb3d5ef3a8541078","timestamp":1728496472137}]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9fn4V0dbJ7q","executionInfo":{"status":"ok","timestamp":1730442218249,"user_tz":-330,"elapsed":21503,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"11489fba-a71b-4ec0-f62f-089e37e1f210"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install mne"],"metadata":{"execution":{"iopub.status.busy":"2024-10-09T17:53:35.202953Z","iopub.execute_input":"2024-10-09T17:53:35.203478Z","iopub.status.idle":"2024-10-09T17:53:42.934562Z","shell.execute_reply.started":"2024-10-09T17:53:35.20344Z","shell.execute_reply":"2024-10-09T17:53:42.93329Z"},"trusted":true,"id":"YS71T6SEanq0","outputId":"7280cef3-d31e-49fd-c4d7-da3d8ee34389","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730442223421,"user_tz":-330,"elapsed":5175,"user":{"displayName":"aditya","userId":"15779203425089853693"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mne\n","  Downloading mne-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n","Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n","Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.8.0)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n","Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.6)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (3.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.8.30)\n","Downloading mne-1.8.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: mne\n","Successfully installed mne-1.8.0\n"]}]},{"cell_type":"code","source":["!pip install scipy"],"metadata":{"execution":{"iopub.status.busy":"2024-10-09T17:53:42.937022Z","iopub.execute_input":"2024-10-09T17:53:42.93736Z","iopub.status.idle":"2024-10-09T17:53:44.826672Z","shell.execute_reply.started":"2024-10-09T17:53:42.937324Z","shell.execute_reply":"2024-10-09T17:53:44.825726Z"},"trusted":true,"id":"uvDrCPZ9anq2","outputId":"d975c2b5-e94f-475e-b8cf-386adff947ae","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729618490586,"user_tz":-330,"elapsed":4957,"user":{"displayName":"aditya","userId":"15779203425089853693"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"]}]},{"cell_type":"code","source":["!pip install antropy"],"metadata":{"execution":{"iopub.status.busy":"2024-10-09T17:53:44.828214Z","iopub.execute_input":"2024-10-09T17:53:44.828572Z"},"trusted":true,"id":"cwasIke_anq2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729618497375,"user_tz":-330,"elapsed":6792,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"0b84c359-99d5-406a-e338-aec6dbe0c339"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: antropy in /usr/local/lib/python3.10/dist-packages (0.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from antropy) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from antropy) (1.13.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from antropy) (1.5.2)\n","Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from antropy) (0.60.0)\n","Requirement already satisfied: stochastic in /usr/local/lib/python3.10/dist-packages (from antropy) (0.7.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->antropy) (0.43.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->antropy) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->antropy) (3.5.0)\n"]}]},{"cell_type":"code","source":["!pip install pyEDFlib"],"metadata":{"trusted":true,"id":"QZ3CJNohanq2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729617647146,"user_tz":-330,"elapsed":9098,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"d937a9a9-4497-407c-f12f-c7cac2e451e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyEDFlib\n","  Downloading pyEDFlib-0.1.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pyEDFlib) (1.26.4)\n","Downloading pyEDFlib-0.1.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyEDFlib\n","Successfully installed pyEDFlib-0.1.38\n"]}]},{"cell_type":"code","source":["\n","!pip install git+https://github.com/forrestbao/pyeeg.git"],"metadata":{"trusted":true,"id":"eAf7eCNBanq2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729617659632,"user_tz":-330,"elapsed":12488,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"e86c17fa-d4e7-4b46-87bb-0e1157da762a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/forrestbao/pyeeg.git\n","  Cloning https://github.com/forrestbao/pyeeg.git to /tmp/pip-req-build-u_2azb3p\n","  Running command git clone --filter=blob:none --quiet https://github.com/forrestbao/pyeeg.git /tmp/pip-req-build-u_2azb3p\n","  Resolved https://github.com/forrestbao/pyeeg.git to commit a6c18bb093e4748f9d9c208535a6ae024a0802b8\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from pyeeg==0.4.4) (1.26.4)\n","Building wheels for collected packages: pyeeg\n","  Building wheel for pyeeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28112 sha256=d598761becc16a9b427086912947762da4ecd2da7ff09ae51a8d2e8297117429\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-knq3otnc/wheels/a8/c4/1a/cee09dcc12a11620066d35ace42e3c1e3bfbcc1db3a0ce7788\n","Successfully built pyeeg\n","Installing collected packages: pyeeg\n","Successfully installed pyeeg-0.4.4\n"]}]},{"cell_type":"code","source":["!pip3 install scipy"],"metadata":{"trusted":true,"id":"GccFPObNanq2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729618503799,"user_tz":-330,"elapsed":6427,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"7525f23e-6d42-4b11-8217-bd5bb6c4f706"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"]}]},{"cell_type":"code","source":["# import mne\n","# import numpy as np\n","# import pandas as pd\n","# # from scipy.integrate import simps\n","# from mne.time_frequency import psd_array_multitaper\n","# from pyeeg import hjorth\n","# from antropy import spectral_entropy, sample_entropy\n","# from pyedflib import EdfReader\n","# import math"],"metadata":{"trusted":true,"id":"r6pwj-g0anq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# # Define frequency bands\n","# bands = {\n","#     'delta': (0.5, 4),\n","#     'theta': (4, 8),\n","#     'alpha': (8, 13),\n","#     'beta': (13, 30)\n","# }\n"],"metadata":{"trusted":true,"id":"oYJB0z_panq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from scipy.integrate import simpson\n","# from mne.time_frequency import psd_array_multitaper\n","# import numpy as np\n","\n","# # Function to compute Relative Bandpower with optimizations\n","# def bandpower(data, sf, band, window_sec=None, relative=False, bandwidth=2.0, fmin=0.5, fmax=30):\n","#     band = np.asarray(band)\n","#     low, high = band\n","\n","#     # Set the multitaper bandwidth using the 'bandwidth' argument\n","#     psd, freqs = psd_array_multitaper(data, sf, adaptive=True, normalization='full',\n","#                                       bandwidth=bandwidth, fmin=fmin, fmax=fmax, verbose=False)\n","\n","#     # Find band range\n","#     idx_band = np.logical_and(freqs >= low, freqs <= high)\n","#     bp = simpson(psd[idx_band], dx=np.diff(freqs)[0])\n","\n","#     if relative:\n","#         bp /= simpson(psd, dx=np.diff(freqs)[0])\n","#     return bp\n"],"metadata":{"trusted":true,"id":"eA3TVwvaanq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Function to compute Higuchi Fractal Dimension\n","# def higuchi_fd(data, kmax=10):\n","#     N = len(data)\n","#     Lmk = np.zeros((kmax, kmax))\n","#     for k in range(1, kmax + 1):\n","#         for m in range(k):\n","#             Lm = 0\n","#             for i in range(1, math.floor((N - m) / k)):\n","#                 Lm += abs(data[m + i * k] - data[m + (i - 1) * k])\n","#             Lmk[m, k - 1] = (Lm * (N - 1) / ((math.floor((N - m) / k)) * k)) * (N / k)\n","#     Lk = np.zeros(kmax)\n","#     for k in range(1, kmax + 1):\n","#         Lk[k - 1] = np.mean(Lmk[:k, k - 1])\n","#     lnLk = np.log(Lk)\n","#     lnk = np.log(1. / np.arange(1, kmax + 1))\n","#     higuchi = np.polyfit(lnk, lnLk, 1)[0]\n","#     return higuchi"],"metadata":{"trusted":true,"id":"4wc6-JUBanq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Function to compute Alpha/Beta, Theta/Alpha Ratios\n","# def ratio_features(bp_alpha, bp_beta, bp_theta):\n","#     alpha_beta_ratio = bp_alpha / bp_beta\n","#     theta_alpha_ratio = bp_theta / bp_alpha\n","#     return alpha_beta_ratio, theta_alpha_ratio"],"metadata":{"trusted":true,"id":"7Y3RiNKSanq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Function to process a single channel of EEG data\n","# def extract_features(raw, sf):\n","#     mobility=[]\n","#     complexity=[]\n","#     higuchi=[]\n","#     spec_entropy=[]\n","#     samp_entropy=[]\n","#     bp_delta=[]\n","#     bp_theta=[]\n","#     bp_alpha=[]\n","#     bp_beta=[]\n","#     alpha_beta_ratio=[]\n","#     theta_alpha_ratio=[]\n","#     # Hjorth Parameters\n","#     data, _ = raw[:, :]  # Get all channels data\n","\n","#     # Extract features for each channel and store them in corresponding DataFrames\n","#     for i, channel_data in enumerate(data):\n","#         hj=hjorth(channel_data)\n","#         mobility.append(hj[0])\n","#         complexity.append(hj[1])\n","\n","#         # Higuchi Fractal Dimension\n","#         higuchi.append(higuchi_fd(channel_data))\n","\n","#         # Spectral Entropy (antropy library)\n","#         spec_entropy .append( spectral_entropy(channel_data, sf, method='welch', normalize=True))\n","\n","#         # Sample Entropy (antropy library)\n","#         samp_entropy .append( sample_entropy(channel_data, order=2))\n","\n","#         # Relative Bandpower\n","#         bp_alpha_data=bandpower(channel_data, sf, bands['alpha'], relative=True)\n","#         bp_delta_data=bandpower(channel_data, sf, bands['delta'], relative=True)\n","#         bp_theta_data=bandpower(channel_data, sf, bands['theta'], relative=True)\n","#         bp_beta_data=bandpower(channel_data, sf, bands['beta'], relative=True)\n","\n","#         bp_delta .append(bp_delta_data)\n","#         bp_theta .append(bp_theta_data)\n","#         bp_alpha .append( bp_alpha_data)\n","#         bp_beta .append(bp_beta_data)\n","\n","#         # Alpha/Beta and Theta/Alpha Ratios\n","\n","#         rf=ratio_features(bp_alpha_data, bp_beta_data, bp_theta_data)\n","#         alpha_beta_ratio.append(rf[0])\n","#         theta_alpha_ratio.append(rf[1])\n","\n","#     # Store features in a dictionary\n","#     features = {\n","#         'Hjorth_Mobility': mobility,\n","#         'Hjorth_Complexity': complexity,\n","#         'Higuchi_FD': higuchi,\n","#         'Spectral_Entropy': spec_entropy,\n","#         'Sample_Entropy': samp_entropy,\n","#         'Delta_Rel_Bandpower': bp_delta,\n","#         'Theta_Rel_Bandpower': bp_theta,\n","#         'Alpha_Rel_Bandpower': bp_alpha,\n","#         'Beta_Rel_Bandpower': bp_beta,\n","#         'Alpha_Beta_Ratio': alpha_beta_ratio,\n","#         'Theta_Alpha_Ratio': theta_alpha_ratio\n","#     }\n","\n","#     return features\n","\n","# # Main function to read EDF file and process data"],"metadata":{"trusted":true,"id":"CPs5nEiganq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os"],"metadata":{"trusted":true,"id":"5VwjWc1lanq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def process_edf_folder(folder_path,y,z):\n","#     # DataFrames to store results for each feature across all EDF files\n","#     df_hjorth_mobility = pd.DataFrame()\n","#     df_hjorth_complexity = pd.DataFrame()\n","#     df_higuchi_fd = pd.DataFrame()\n","#     df_spectral_entropy = pd.DataFrame()\n","#     df_sample_entropy = pd.DataFrame()\n","#     df_delta_bandpower = pd.DataFrame()\n","#     df_theta_bandpower = pd.DataFrame()\n","#     df_alpha_bandpower = pd.DataFrame()\n","#     df_beta_bandpower = pd.DataFrame()\n","#     df_alpha_beta_ratio = pd.DataFrame()\n","#     df_theta_alpha_ratio = pd.DataFrame()\n","\n","#     # Loop through each EDF file in the folder\n","#     for file_name in os.listdir(folder_path):\n","#         if file_name.endswith('.edf'):\n","#             y.append(z)\n","#             edf_path = os.path.join(folder_path, file_name)\n","\n","#             # Read the EDF file using mne\n","#             raw = mne.io.read_raw_edf(edf_path, preload=True)\n","#             sf = raw.info['sfreq']  # Sampling frequency\n","\n","#             features = extract_features(raw, sf)\n","\n","\n","#             # Create a Series for each feature\n","#             mobility_series = pd.Series(features['Hjorth_Mobility'],  name=file_name)\n","#             complexity_series = pd.Series(features['Hjorth_Complexity'],name=file_name)\n","#             higuchi_series = pd.Series(features['Higuchi_FD'], name=file_name)\n","#             spectral_entropy_series = pd.Series(features['Spectral_Entropy'],  name=file_name)\n","#             sample_entropy_series = pd.Series(features['Sample_Entropy'], name=file_name)\n","#             delta_bandpower_series = pd.Series(features['Delta_Rel_Bandpower'],  name=file_name)\n","#             theta_bandpower_series = pd.Series(features['Theta_Rel_Bandpower'],name=file_name)\n","#             alpha_bandpower_series = pd.Series(features['Alpha_Rel_Bandpower'],name=file_name)\n","#             beta_bandpower_series = pd.Series(features['Beta_Rel_Bandpower'], name=file_name)\n","#             alpha_beta_ratio_series = pd.Series(features['Alpha_Beta_Ratio'], name=file_name)\n","#             theta_alpha_ratio_series = pd.Series(features['Theta_Alpha_Ratio'],  name=file_name)\n","\n","#             # Concatenate each feature Series into the DataFrames\n","#             df_hjorth_mobility = pd.concat([df_hjorth_mobility, mobility_series.to_frame().T])\n","#             df_hjorth_complexity = pd.concat([df_hjorth_complexity, complexity_series.to_frame().T])\n","#             df_higuchi_fd = pd.concat([df_higuchi_fd, higuchi_series.to_frame().T])\n","#             df_spectral_entropy = pd.concat([df_spectral_entropy, spectral_entropy_series.to_frame().T])\n","#             df_sample_entropy = pd.concat([df_sample_entropy, sample_entropy_series.to_frame().T])\n","#             df_delta_bandpower = pd.concat([df_delta_bandpower, delta_bandpower_series.to_frame().T])\n","#             df_theta_bandpower = pd.concat([df_theta_bandpower, theta_bandpower_series.to_frame().T])\n","#             df_alpha_bandpower = pd.concat([df_alpha_bandpower, alpha_bandpower_series.to_frame().T])\n","#             df_beta_bandpower = pd.concat([df_beta_bandpower, beta_bandpower_series.to_frame().T])\n","#             df_alpha_beta_ratio = pd.concat([df_alpha_beta_ratio, alpha_beta_ratio_series.to_frame().T])\n","#             df_theta_alpha_ratio = pd.concat([df_theta_alpha_ratio, theta_alpha_ratio_series.to_frame().T])\n","\n","#     return {\n","#         'Hjorth_Mobility': df_hjorth_mobility,\n","#         'Hjorth_Complexity': df_hjorth_complexity,\n","#         'Higuchi_FD': df_higuchi_fd,\n","#         'Spectral_Entropy': df_spectral_entropy,\n","#         'Sample_Entropy': df_sample_entropy,\n","#         'Delta_Bandpower': df_delta_bandpower,\n","#         'Theta_Bandpower': df_theta_bandpower,\n","#         'Alpha_Bandpower': df_alpha_bandpower,\n","#         'Beta_Bandpower': df_beta_bandpower,\n","#         'Alpha_Beta_Ratio': df_alpha_beta_ratio,\n","#         'Theta_Alpha_Ratio': df_theta_alpha_ratio\n","#     }\n"],"metadata":{"trusted":true,"id":"LnEC0Pqqanq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base1=\"/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT\"\n","base2=\"/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT\""],"metadata":{"trusted":true,"id":"i6p3Kzj0anq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Example usage\n","# edf_path = 'Subject01_1.edf'\n","# y=[]\n","# features_dfs_before=process_edf_folder(base1,y,0)\n","# features_dfs_during = process_edf_folder(base2,y,1)\n","\n","# # # Example to access one of the DataFrames\n","# # print(features_dfs['Hjorth_Mobility'])\n"],"metadata":{"trusted":true,"id":"vJG0MuRVanq5","colab":{"base_uri":"https://localhost:8080/","height":218},"executionInfo":{"status":"error","timestamp":1728496848052,"user_tz":-330,"elapsed":463,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"75ddd19c-ced4-428d-a4d7-4f24ab43e44a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'process_edf_folder' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-c6a569bdee84>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0medf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Subject01_1.edf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeatures_dfs_before\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_edf_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfeatures_dfs_during\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_edf_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'process_edf_folder' is not defined"]}]},{"cell_type":"code","source":["# X={}\n","# before=list(features_dfs_before.items())\n","# during=list(features_dfs_during.items())\n","# for i in range(len(before)):\n","#     X[before[i][0]]=pd.concat((before[i][1],during[i][1]),axis=0)\n"],"metadata":{"trusted":true,"id":"Yz_6o18sanq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for item in X.items():\n","#     item[1].to_csv(f'{item[0]}.csv')"],"metadata":{"trusted":true,"id":"k1EpBXpOanq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# y=pd.DataFrame(y)\n","# y.to_csv(\"y.csv\")"],"metadata":{"trusted":true,"id":"qr8-YM0kanq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# import mne\n","# import pandas as pd\n","\n","# # Function to extract features from a single channel of EEG data\n","# def extract_features(raw, sf):\n","#     mobility = []\n","#     complexity = []\n","#     higuchi = []\n","#     spec_entropy = []\n","#     samp_entropy = []\n","#     bp_delta = []\n","#     bp_theta = []\n","#     bp_alpha = []\n","#     bp_beta = []\n","#     alpha_beta_ratio = []\n","#     theta_alpha_ratio = []\n","\n","#     data, _ = raw[:, :]  # Get all channels data\n","\n","#     # Extract features for each channel\n","#     for channel_data in data:\n","#         hj = hjorth(channel_data)\n","#         mobility.append(hj[0])\n","#         complexity.append(hj[1])\n","\n","#         # Higuchi Fractal Dimension\n","#         higuchi.append(higuchi_fd(channel_data))\n","\n","#         # Spectral Entropy\n","#         spec_entropy.append(spectral_entropy(channel_data, sf, method='welch', normalize=True))\n","\n","#         # Sample Entropy\n","#         samp_entropy.append(sample_entropy(channel_data, order=2))\n","\n","#         # Relative Bandpower\n","#         bp_alpha_data = bandpower(channel_data, sf, bands['alpha'], relative=True)\n","#         bp_delta_data = bandpower(channel_data, sf, bands['delta'], relative=True)\n","#         bp_theta_data = bandpower(channel_data, sf, bands['theta'], relative=True)\n","#         bp_beta_data = bandpower(channel_data, sf, bands['beta'], relative=True)\n","\n","#         bp_delta.append(bp_delta_data)\n","#         bp_theta.append(bp_theta_data)\n","#         bp_alpha.append(bp_alpha_data)\n","#         bp_beta.append(bp_beta_data)\n","\n","#         # Alpha/Beta and Theta/Alpha Ratios\n","#         rf = ratio_features(bp_alpha_data, bp_beta_data, bp_theta_data)\n","#         alpha_beta_ratio.append(rf[0])\n","#         theta_alpha_ratio.append(rf[1])\n","\n","#     # Return extracted features\n","#     return {\n","#         'Hjorth_Mobility': mobility,\n","#         'Hjorth_Complexity': complexity,\n","#         'Higuchi_FD': higuchi,\n","#         'Spectral_Entropy': spec_entropy,\n","#         'Sample_Entropy': samp_entropy,\n","#         'Delta_Rel_Bandpower': bp_delta,\n","#         'Theta_Rel_Bandpower': bp_theta,\n","#         'Alpha_Rel_Bandpower': bp_alpha,\n","#         'Beta_Rel_Bandpower': bp_beta,\n","#         'Alpha_Beta_Ratio': alpha_beta_ratio,\n","#         'Theta_Alpha_Ratio': theta_alpha_ratio\n","#     }\n","\n","# # Function to process each EDF file and save each feature to a CSV file\n","# def process_and_save_features(folder_path, output_folder, y_value):\n","#     # Ensure the output folder exists\n","#     if not os.path.exists(output_folder):\n","#         os.makedirs(output_folder)\n","\n","#     # Loop through each EDF file in the folder\n","#     for file_name in os.listdir(folder_path):\n","#         if file_name.endswith('.edf'):\n","#             edf_path = os.path.join(folder_path, file_name)\n","\n","#             # Read the EDF file using mne\n","#             raw = mne.io.read_raw_edf(edf_path, preload=True)\n","#             sf = raw.info['sfreq']  # Sampling frequency\n","\n","#             # Extract features\n","#             features = extract_features(raw, sf)\n","\n","#             # Save each feature to a CSV file\n","#             for feature_name, feature_data in features.items():\n","#                 # Convert to DataFrame\n","#                 df = pd.DataFrame(feature_data)\n","#                 # Set file name for the CSV file\n","#                 output_file = os.path.join(output_folder, f\"{feature_name}_{file_name.replace('.edf', '')}.csv\")\n","#                 # Save DataFrame to CSV\n","#                 df.to_csv(output_file, index=False)\n","\n","#             print(f\"Features for {file_name} saved to CSV.\")\n","\n","# # Example usage\n","# # base1 = '/kaggle/input/mat-dataset/MAT_dataset/before_MAT'\n","# # base2 = '/kaggle/input/mat-dataset/MAT_dataset/during_MAT'\n","# output_folder1 = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/extracted_features_long'\n","# output_folder2 = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/extracted_features_long'\n","\n","# # Process and save features for each EDF file in the two folders\n","# process_and_save_features(base1, output_folder1, 0)\n","# process_and_save_features(base2, output_folder2, 1)\n"],"metadata":{"trusted":true,"id":"AQLnDKu-anq5","colab":{"base_uri":"https://localhost:8080/","height":200},"outputId":"909261c2-d1b6-43de-bc6c-4d7a5187bd3f","executionInfo":{"status":"error","timestamp":1728636666200,"user_tz":-330,"elapsed":1934,"user":{"displayName":"aditya","userId":"15779203425089853693"}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'base1' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-b4ae727fce4a>\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# Process and save features for each EDF file in the two folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mprocess_and_save_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0mprocess_and_save_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'base1' is not defined"]}]},{"cell_type":"markdown","source":["extracting hjorth"],"metadata":{"id":"ND12zo2CwRlX"}},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","from glob import glob\n","\n","# Define Hjorth functions\n","def hjorth_parameters(eeg_data):\n","    \"\"\"\n","    Compute Hjorth parameters (Activity, Mobility, Complexity) for a signal.\n","\n","    Args:\n","        eeg_data (ndarray): 1D array representing the EEG signal for a single channel.\n","\n","    Returns:\n","        tuple: A tuple containing Hjorth Activity, Mobility, and Complexity.\n","    \"\"\"\n","    # Hjorth Activity\n","    activity = np.var(eeg_data)\n","\n","    # Hjorth Mobility\n","    deriv_1 = np.diff(eeg_data)\n","    mobility = np.sqrt(np.var(deriv_1) / activity)\n","\n","    # Hjorth Complexity\n","    deriv_2 = np.diff(deriv_1)\n","    complexity = np.sqrt((np.var(deriv_2) / np.var(deriv_1)) / mobility)\n","\n","    return activity, mobility, complexity\n","\n","def extract_hjorth_features(edf_file):\n","    \"\"\"\n","    Extract Hjorth features (Activity, Mobility, Complexity) from EEG data in an EDF file.\n","\n","    Args:\n","        edf_file (str): Path to the .edf file.\n","\n","    Returns:\n","        tuple: Activity, Mobility, and Complexity DataFrames for the given EDF file.\n","    \"\"\"\n","    # Load the EDF file using MNE\n","    raw = mne.io.read_raw_edf(edf_file, preload=True)\n","\n","    # Get the EEG data (picks only EEG channels)\n","    eeg_data = raw.get_data(picks='eeg')\n","\n","    # Get channel names\n","    channel_names = raw.ch_names\n","\n","    # Initialize lists to store Hjorth features\n","    activity_data = [os.path.basename(edf_file)]\n","    mobility_data = [os.path.basename(edf_file)]\n","    complexity_data = [os.path.basename(edf_file)]\n","\n","    # Loop through each channel and compute Hjorth parameters\n","    for idx, channel in enumerate(channel_names):\n","        channel_data = eeg_data[idx, :]\n","\n","        # Compute Hjorth features\n","        activity, mobility, complexity = hjorth_parameters(channel_data)\n","\n","        # Append each feature to corresponding list\n","        activity_data.append(activity)\n","        mobility_data.append(mobility)\n","        complexity_data.append(complexity)\n","\n","    return activity_data, mobility_data, complexity_data, channel_names\n","\n","def process_multiple_edf_files(edf_dir, output_dir):\n","    \"\"\"\n","    Process multiple EDF files in a directory and extract Hjorth features for each.\n","\n","    Args:\n","        edf_dir (str): Directory containing the .edf files.\n","        output_dir (str): Directory where the CSV files will be saved.\n","    \"\"\"\n","    # Get a list of all .edf files in the directory\n","    edf_files = glob(os.path.join(edf_dir, '*.edf'))\n","\n","    # Initialize lists to store Hjorth data for all files\n","    all_activity = []\n","    all_mobility = []\n","    all_complexity = []\n","\n","    # Process each EDF file\n","    for edf_file in edf_files:\n","        print(f\"Processing file: {edf_file}\")\n","\n","        # Extract Hjorth features for the current file\n","        activity_data, mobility_data, complexity_data, channel_names = extract_hjorth_features(edf_file)\n","\n","        # Append results to overall lists\n","        all_activity.append(activity_data)\n","        all_mobility.append(mobility_data)\n","        all_complexity.append(complexity_data)\n","\n","    # Create DataFrames for each feature\n","    first_column = ['EDF File'] + channel_names\n","    activity_df = pd.DataFrame(all_activity, columns=first_column)\n","    mobility_df = pd.DataFrame(all_mobility, columns=first_column)\n","    complexity_df = pd.DataFrame(all_complexity, columns=first_column)\n","\n","    # Save the DataFrames to CSV files\n","    activity_df.to_csv(os.path.join(output_dir, 'all_files_activity.csv'), index=False)\n","    mobility_df.to_csv(os.path.join(output_dir, 'all_files_mobility.csv'), index=False)\n","    complexity_df.to_csv(os.path.join(output_dir, 'all_files_complexity.csv'), index=False)\n","\n","# Example usage:\n","# Replace 'edf_directory' with the folder containing your .edf files,\n","# and 'output_directory' with the folder where you want to save the CSVs.\n","\n","edf_directory = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT'  # Directory containing the EDF files\n","output_directory = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/extracted_features_long/before'  # Directory to store the CSVs\n","\n","# Create the output directory if it doesn't exist\n","os.makedirs(output_directory, exist_ok=True)\n","\n","# Process all .edf files in the directory\n","process_multiple_edf_files(edf_directory, output_directory)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"paKatsAPwQ9o","executionInfo":{"status":"ok","timestamp":1728637759296,"user_tz":-330,"elapsed":9754,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"64ea4c26-0faa-4158-ea19-0a88d1057011"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject12_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject12_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject11_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject11_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject01_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject01_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject13_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject13_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject10_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject10_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 93999  =      0.000 ...   187.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject14_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject14_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject18_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject18_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject02_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject02_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject15_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject15_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject16_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject16_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject19_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject19_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject25_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject25_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject26_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject26_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject24_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject24_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject20_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject20_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject21_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject21_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject29_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject29_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject32_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject32_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject28_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject28_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject03_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject03_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject30_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject30_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject27_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject27_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject06_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject06_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject04_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject04_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 84999  =      0.000 ...   169.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject34_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject34_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject35_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject35_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject33_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject33_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject07_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject07_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject05_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject05_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject09_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject09_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject08_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject08_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject31_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject31_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 39999  =      0.000 ...    79.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject17_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject17_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject22_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject22_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject00_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject00_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n","Processing file: /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject23_1.edf\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/before_MAT/Subject23_1.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 90999  =      0.000 ...   181.998 secs...\n"]}]},{"cell_type":"markdown","source":[" Higuchi Fractal Dimension"],"metadata":{"id":"-zXjlJ23zn7z"}},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","def higuchi_fd(signal, kmax):\n","    \"\"\"\n","    Calculate the Higuchi Fractal Dimension (HFD) of a signal.\n","\n","    Args:\n","        signal (ndarray): 1D array representing the EEG signal for a single channel.\n","        kmax (int): The maximum number of intervals (k) to use for the HFD calculation.\n","\n","    Returns:\n","        float: The Higuchi Fractal Dimension of the signal.\n","    \"\"\"\n","    L = []\n","    N = len(signal)\n","\n","    for k in range(1, kmax + 1):\n","        Lk = []\n","        for m in range(k):\n","            Lmk = 0\n","            for i in range(1, int(np.floor((N - m) / k))):\n","                Lmk += abs(signal[m + i * k] - signal[m + (i - 1) * k])\n","            Lmk = (Lmk * (N - 1) / ((N - m) * k)) / k\n","            Lk.append(Lmk)\n","        L.append(np.mean(Lk))\n","\n","    # Linear fit to log-log plot (log(L) vs log(1/k))\n","    logL = np.log(L)\n","    logk = np.log(np.arange(1, kmax + 1))\n","    higuchi_dim = np.polyfit(logk, logL, 1)[0]\n","\n","    return higuchi_dim\n","\n","def extract_hfd_from_folder(edf_folder, kmax, output_csv):\n","    \"\"\"\n","    Extract Higuchi Fractal Dimension (HFD) from multiple EEG EDF files in a folder and store them in one CSV file.\n","\n","    Args:\n","        edf_folder (str): Path to the folder containing the .edf files.\n","        kmax (int): Maximum k value for HFD calculation.\n","        output_csv (str): Path to save the CSV file containing the HFD values for all files.\n","    \"\"\"\n","    # Initialize an empty DataFrame to store the results\n","    all_hfd_df = pd.DataFrame()\n","\n","    # Loop through each EDF file in the folder\n","    for file_name in os.listdir(edf_folder):\n","        if file_name.endswith('.edf'):\n","            edf_file_path = os.path.join(edf_folder, file_name)\n","\n","            # Load the EDF file using MNE\n","            raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n","\n","            # Get the EEG data (picks only EEG channels)\n","            eeg_data = raw.get_data(picks='eeg')\n","\n","            # Get channel names\n","            channel_names = raw.ch_names\n","\n","            # Initialize a dictionary to store HFD values for the current file\n","            hfd_values = {}\n","\n","            # Extract the file name (without extension) to use as the row label\n","            file_base_name = os.path.basename(edf_file_path).replace('.edf', '')\n","\n","            # Loop through each channel and compute HFD\n","            for idx, channel in enumerate(channel_names):\n","                channel_data = eeg_data[idx, :]\n","\n","                # Compute Higuchi Fractal Dimension\n","                hfd_value = higuchi_fd(channel_data, kmax)\n","\n","                # Add the HFD value for this channel\n","                hfd_values[channel] = hfd_value\n","\n","            # Convert the dictionary of HFD values to a DataFrame (single row)\n","            hfd_df = pd.DataFrame(hfd_values, index=[file_base_name])\n","\n","            # Append the new row to the main DataFrame\n","            all_hfd_df = pd.concat([all_hfd_df, hfd_df])\n","\n","    # Save the final DataFrame to CSV\n","    all_hfd_df.to_csv(output_csv, index=True)\n","\n","# Example usage:\n","# Replace 'edf_folder_path' with the actual folder path containing your .edf files\n","edf_folder_path = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT'  # Change to your actual folder path\n","output_csv_path = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/extracted_features_long/during/hfd_all_files.csv'\n","kmax = 10  # Set the maximum k value for HFD calculation\n","\n","extract_hfd_from_folder(edf_folder_path, kmax, output_csv_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_ZyyHIMznVt","executionInfo":{"status":"ok","timestamp":1728638668324,"user_tz":-330,"elapsed":205272,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"1685fb3e-6b09-4d40-b2a7-c1e10f02ce14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject11_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject12_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject10_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject02_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject18_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject16_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject19_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject17_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject21_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject23_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject26_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject22_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject25_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject24_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject32_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject30_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject33_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject27_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject28_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject29_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject07_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject34_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject08_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject04_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject06_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject09_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject01_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject35_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject05_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject20_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject03_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject15_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject14_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject00_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject13_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject31_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n"]}]},{"cell_type":"markdown","source":["Spectral ENtropy\n"],"metadata":{"id":"Ze-3kVbg4sCj"}},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","from scipy.signal import welch\n","from scipy.stats import entropy\n","\n","def spectral_entropy(signal, sf, nperseg=None):\n","    \"\"\"\n","    Calculate the Spectral Entropy of a signal.\n","\n","    Args:\n","        signal (ndarray): 1D array representing the EEG signal for a single channel.\n","        sf (float): Sampling frequency of the signal.\n","        nperseg (int, optional): Length of each segment for Welch's method. Defaults to None.\n","\n","    Returns:\n","        float: The Spectral Entropy of the signal.\n","    \"\"\"\n","    # Calculate the Power Spectral Density (PSD) using Welch's method\n","    freqs, psd = welch(signal, sf, nperseg=nperseg)\n","\n","    # Normalize the PSD to get a probability distribution\n","    psd_norm = psd / np.sum(psd)\n","\n","    # Calculate the spectral entropy\n","    spec_entropy = entropy(psd_norm)\n","\n","    return spec_entropy\n","\n","def extract_spectral_entropy_from_folder(edf_folder, output_csv):\n","    \"\"\"\n","    Extract Spectral Entropy from multiple EEG EDF files in a folder and store them in one CSV file.\n","\n","    Args:\n","        edf_folder (str): Path to the folder containing the .edf files.\n","        output_csv (str): Path to save the CSV file containing the Spectral Entropy values for all files.\n","    \"\"\"\n","    # Initialize an empty DataFrame to store the results\n","    all_entropy_df = pd.DataFrame()\n","\n","    # Loop through each EDF file in the folder\n","    for file_name in os.listdir(edf_folder):\n","        if file_name.endswith('.edf'):\n","            edf_file_path = os.path.join(edf_folder, file_name)\n","\n","            # Load the EDF file using MNE\n","            raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n","\n","            # Get the EEG data (picks only EEG channels)\n","            eeg_data = raw.get_data(picks='eeg')\n","\n","            # Get the sampling frequency\n","            sf = raw.info['sfreq']\n","\n","            # Get channel names\n","            channel_names = raw.ch_names\n","\n","            # Initialize a dictionary to store Spectral Entropy values for the current file\n","            entropy_values = {}\n","\n","            # Extract the file name (without extension) to use as the row label\n","            file_base_name = os.path.basename(edf_file_path).replace('.edf', '')\n","\n","            # Loop through each channel and compute Spectral Entropy\n","            for idx, channel in enumerate(channel_names):\n","                channel_data = eeg_data[idx, :]\n","\n","                # Compute Spectral Entropy\n","                entropy_value = spectral_entropy(channel_data, sf)\n","\n","                # Add the entropy value for this channel\n","                entropy_values[channel] = entropy_value\n","\n","            # Convert the dictionary of Spectral Entropy values to a DataFrame (single row)\n","            entropy_df = pd.DataFrame(entropy_values, index=[file_base_name])\n","\n","            # Append the new row to the main DataFrame\n","            all_entropy_df = pd.concat([all_entropy_df, entropy_df])\n","\n","    # Save the final DataFrame to CSV\n","    all_entropy_df.to_csv(output_csv, index=True)\n","\n","# Example usage:\n","# Replace 'edf_folder_path' with the actual folder path containing your .edf files\n","edf_folder_path = '/kaggle/input/mat-dataset/MAT_dataset/during_MAT'  # Change to your actual folder path\n","output_csv_path = 'spectral_entropy_all_files_during.csv'\n","\n","extract_spectral_entropy_from_folder(edf_folder_path, output_csv_path)\n"],"metadata":{"id":"LKIt8yOG4uPN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sample Entropy\n"],"metadata":{"id":"d2UbgsFv4vmZ"}},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","def sample_entropy(signal, m=2, r=0.2):\n","    \"\"\"\n","    Calculate the Sample Entropy of a signal.\n","\n","    Args:\n","        signal (ndarray): 1D array representing the EEG signal for a single channel.\n","        m (int): Length of sequences to compare.\n","        r (float): Tolerance for accepting matches (typically 0.2 times the standard deviation of the signal).\n","\n","    Returns:\n","        float: Sample Entropy of the signal.\n","    \"\"\"\n","    # Preprocessing signal: removing NaN values\n","    signal = signal[~np.isnan(signal)]\n","\n","    N = len(signal)\n","    if N <= m:\n","        return np.nan  # Not enough data for given m\n","\n","    def _phi(m):\n","        \"\"\"Calculate the number of matching sequences of length m.\"\"\"\n","        x = np.array([signal[i:i + m] for i in range(N - m + 1)])\n","        C = np.sum(np.abs(x[:, None] - x) <= r, axis=(1, 2))\n","        return np.sum(C)\n","\n","    # Calculate phi(m) and phi(m+1)\n","    phi_m = _phi(m)\n","    phi_m1 = _phi(m + 1)\n","\n","    # Calculate Sample Entropy\n","    if phi_m == 0:\n","        return np.nan  # Avoid log(0)\n","\n","    return -np.log(phi_m1 / phi_m)\n","\n","def extract_sample_entropy_from_folder(edf_folder, output_csv):\n","    \"\"\"\n","    Extract Sample Entropy from multiple EEG EDF files in a folder and store them in one CSV file.\n","\n","    Args:\n","        edf_folder (str): Path to the folder containing the .edf files.\n","        output_csv (str): Path to save the CSV file containing the Sample Entropy values for all files.\n","    \"\"\"\n","    # Initialize an empty DataFrame to store the results\n","    sample_entropy_df = pd.DataFrame()\n","\n","    # Loop through each EDF file in the folder\n","    for file_name in os.listdir(edf_folder):\n","        if file_name.endswith('.edf'):\n","            edf_file_path = os.path.join(edf_folder, file_name)\n","\n","            # Load the EDF file using MNE\n","            raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n","\n","            # Get the EEG data (picks only EEG channels)\n","            eeg_data = raw.get_data(picks='eeg')\n","\n","            # Extract the file name (without extension) to use as the row label\n","            file_base_name = os.path.basename(edf_file_path).replace('.edf', '')\n","\n","            # Initialize a dictionary to store Sample Entropy values for the current file\n","            entropy_values = {}\n","\n","            # Loop through each channel and compute Sample Entropy\n","            for idx, channel in enumerate(raw.ch_names):\n","                channel_data = eeg_data[idx, :]\n","\n","                # Compute Sample Entropy\n","                se = sample_entropy(channel_data)\n","\n","                # Store the Sample Entropy value\n","                entropy_values[channel] = se\n","\n","            # Convert the dictionary of Sample Entropy values to a DataFrame (single row)\n","            entropy_df = pd.DataFrame(entropy_values, index=[file_base_name])\n","\n","            # Append the new row to the main DataFrame\n","            sample_entropy_df = pd.concat([sample_entropy_df, entropy_df])\n","\n","    # Save the final DataFrame to CSV\n","    sample_entropy_df.to_csv(output_csv, index=True)\n","\n","# Example usage:\n","# Replace 'edf_folder_path' with the actual folder path containing your .edf files\n","edf_folder_path = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/extracted_features_long/before'  # Change to your actual folder path\n","output_csv_path = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/extracted_features_long/before/sample_entropy_all_files.csv'\n","\n","extract_sample_entropy_from_folder(edf_folder_path, output_csv_path)\n"],"metadata":{"id":"gLv-jMIv4xzg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Relative Bandpower"],"metadata":{"id":"0nP1GeB45awQ"}},{"cell_type":"markdown","source":[],"metadata":{"id":"uoV3XQ549nBe"}},{"cell_type":"code","source":["!pip install --upgrade mne"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwbY9_pU9l8U","executionInfo":{"status":"ok","timestamp":1728639844031,"user_tz":-330,"elapsed":6505,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"b27158fc-f6eb-4cc6-9042-8355f140de89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n","Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n","Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n","Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.8.30)\n"]}]},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","from scipy.signal import welch\n","\n","def relative_bandpower(signal, sf, bands):\n","    \"\"\"\n","    Calculate the relative bandpower of a signal.\n","\n","    Args:\n","        signal (ndarray): 1D array representing the EEG signal for a single channel.\n","        sf (float): Sampling frequency of the signal.\n","        bands (dict): Dictionary containing the frequency bands.\n","\n","    Returns:\n","        dict: Relative bandpower for each frequency band.\n","    \"\"\"\n","    # Calculate the Power Spectral Density (PSD) using Welch's method\n","    freqs, psd = welch(signal, fs=sf, nperseg=256)  # You can adjust nperseg as needed\n","\n","    # Total power\n","    total_power = np.sum(psd)\n","\n","    # Calculate relative bandpower for each band\n","    bandpower = {}\n","    for band, (low, high) in bands.items():\n","        # Find indices of frequencies in the band\n","        idx_band = np.logical_and(freqs >= low, freqs <= high)\n","        # Calculate bandpower\n","        bandpower[band] = np.sum(psd[idx_band]) / total_power if total_power > 0 else 0\n","\n","    return bandpower\n","\n","def extract_relative_bandpower_from_folder(edf_folder, output_csv):\n","    \"\"\"\n","    Extract Relative Bandpower from multiple EEG EDF files in a folder and store them in one CSV file.\n","\n","    Args:\n","        edf_folder (str): Path to the folder containing the .edf files.\n","        output_csv (str): Path to save the CSV file containing the Relative Bandpower values for all files.\n","    \"\"\"\n","    # Define the frequency bands\n","    bands = {\n","        'Delta': (0.5, 4),\n","        'Theta': (4, 8),\n","        'Alpha': (8, 12),\n","        'Beta': (12, 30),\n","        'Gamma': (30, 40)\n","    }\n","\n","    # Initialize an empty DataFrame to store the results\n","    all_bandpower_df = pd.DataFrame()\n","\n","    # Loop through each EDF file in the folder\n","    for file_name in os.listdir(edf_folder):\n","        if file_name.endswith('.edf'):\n","            edf_file_path = os.path.join(edf_folder, file_name)\n","\n","            # Load the EDF file using MNE\n","            raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n","\n","            # Get the EEG data (picks only EEG channels)\n","            eeg_data = raw.get_data(picks='eeg')\n","\n","            # Get the sampling frequency\n","            sf = raw.info['sfreq']\n","\n","            # Get channel names\n","            channel_names = raw.ch_names\n","\n","            # Initialize a dictionary to store Relative Bandpower values for the current file\n","            bandpower_values = {}\n","\n","            # Extract the file name (without extension) to use as the row label\n","            file_base_name = os.path.basename(edf_file_path).replace('.edf', '')\n","\n","            # Loop through each channel and compute Relative Bandpower\n","            for idx, channel in enumerate(channel_names):\n","                channel_data = eeg_data[idx, :]\n","\n","                # Compute Relative Bandpower\n","                bandpower = relative_bandpower(channel_data, sf, bands)\n","\n","                # Add the bandpower values for this channel\n","                for band, value in bandpower.items():\n","                    bandpower_values[f\"{channel}_{band}\"] = value\n","\n","            # Convert the dictionary of Relative Bandpower values to a DataFrame (single row)\n","            bandpower_df = pd.DataFrame(bandpower_values, index=[file_base_name])\n","\n","            # Append the new row to the main DataFrame\n","            all_bandpower_df = pd.concat([all_bandpower_df, bandpower_df])\n","\n","    # Save the final DataFrame to CSV\n","    all_bandpower_df.to_csv(output_csv, index=True)\n","\n","# Example usage:\n","# Replace 'edf_folder_path' with the actual folder path containing your .edf files\n","edf_folder_path = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT'  # Change to your actual folder path\n","output_csv_path = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/extracted_features_long/during/relative_bandpower_all_files.csv'\n","\n","extract_relative_bandpower_from_folder(edf_folder_path, output_csv_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVMTp_Ji5btp","executionInfo":{"status":"ok","timestamp":1728639988681,"user_tz":-330,"elapsed":5158,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"e9e1099d-84fa-4b29-aa6a-122c83621cd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject11_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject12_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject10_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject02_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject18_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject16_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject19_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject17_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject21_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject23_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject26_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject22_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject25_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject24_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject32_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject30_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject33_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject27_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject28_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject29_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject07_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject34_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject08_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject04_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject06_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject09_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject01_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject35_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject05_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject20_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject03_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject15_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject14_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject00_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject13_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject31_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n"]}]},{"cell_type":"markdown","source":["AlphaBeta ThetaAlpha Ratios"],"metadata":{"id":"H-YtfR7a_Wqs"}},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","from scipy.signal import welch\n","\n","def bandpower(signal, sf, bands):\n","    \"\"\"\n","    Calculate the bandpower of a signal in specified frequency bands.\n","\n","    Args:\n","        signal (ndarray): 1D array representing the EEG signal for a single channel.\n","        sf (float): Sampling frequency of the signal.\n","        bands (dict): Dictionary containing the frequency bands.\n","\n","    Returns:\n","        dict: Bandpower for each frequency band.\n","    \"\"\"\n","    # Calculate the Power Spectral Density (PSD) using Welch's method\n","    freqs, psd = welch(signal, fs=sf, nperseg=256)  # You can adjust nperseg as needed\n","\n","    # Calculate bandpower for each band\n","    bandpower_values = {}\n","    for band, (low, high) in bands.items():\n","        # Find indices of frequencies in the band\n","        idx_band = np.logical_and(freqs >= low, freqs <= high)\n","        # Calculate bandpower\n","        bandpower_values[band] = np.sum(psd[idx_band])\n","\n","    return bandpower_values\n","\n","def extract_ratios_from_folder(edf_folder, output_csv):\n","    \"\"\"\n","    Extract Alpha/Beta and Theta/Alpha ratios from multiple EEG EDF files in a folder and store them in one CSV file.\n","\n","    Args:\n","        edf_folder (str): Path to the folder containing the .edf files.\n","        output_csv (str): Path to save the CSV file containing the ratios for all files.\n","    \"\"\"\n","    # Define the frequency bands\n","    bands = {\n","        'Alpha': (8, 12),\n","        'Beta': (12, 30),\n","        'Theta': (4, 8)\n","    }\n","\n","    # Initialize an empty DataFrame to store the results\n","    ratios_df = pd.DataFrame()\n","\n","    # Loop through each EDF file in the folder\n","    for file_name in os.listdir(edf_folder):\n","        if file_name.endswith('.edf'):\n","            edf_file_path = os.path.join(edf_folder, file_name)\n","\n","            # Load the EDF file using MNE\n","            raw = mne.io.read_raw_edf(edf_file_path, preload=True)\n","\n","            # Get the EEG data (picks only EEG channels)\n","            eeg_data = raw.get_data(picks='eeg')\n","\n","            # Get the sampling frequency\n","            sf = raw.info['sfreq']\n","\n","            # Get channel names\n","            channel_names = raw.ch_names\n","\n","            # Initialize a dictionary to store ratios for the current file\n","            ratio_values = {}\n","\n","            # Extract the file name (without extension) to use as the row label\n","            file_base_name = os.path.basename(edf_file_path).replace('.edf', '')\n","\n","            # Loop through each channel and compute the ratios\n","            for idx, channel in enumerate(channel_names):\n","                channel_data = eeg_data[idx, :]\n","\n","                # Compute bandpower for the channel\n","                bandpower_values = bandpower(channel_data, sf, bands)\n","\n","                # Calculate Alpha/Beta and Theta/Alpha ratios\n","                alpha_beta_ratio = bandpower_values['Alpha'] / bandpower_values['Beta'] if bandpower_values['Beta'] > 0 else 0\n","                theta_alpha_ratio = bandpower_values['Theta'] / bandpower_values['Alpha'] if bandpower_values['Alpha'] > 0 else 0\n","\n","                # Store the ratios\n","                ratio_values[f\"{channel}_Alpha_Beta\"] = alpha_beta_ratio\n","                ratio_values[f\"{channel}_Theta_Alpha\"] = theta_alpha_ratio\n","\n","            # Convert the dictionary of ratios to a DataFrame (single row)\n","            ratio_df = pd.DataFrame(ratio_values, index=[file_base_name])\n","\n","            # Append the new row to the main DataFrame\n","            ratios_df = pd.concat([ratios_df, ratio_df])\n","\n","    # Save the final DataFrame to CSV\n","    ratios_df.to_csv(output_csv, index=True)\n","\n","# Example usage:\n","# Replace 'edf_folder_path' with the actual folder path containing your .edf files\n","edf_folder_path = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT'  # Change to your actual folder path\n","output_csv_path = '/content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/extracted_features_long/during/ratios_alpha_beta_theta_alpha.csv'\n","\n","extract_ratios_from_folder(edf_folder_path, output_csv_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YgfyQpc2_Xd7","executionInfo":{"status":"ok","timestamp":1728640368582,"user_tz":-330,"elapsed":5721,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"006aa5ae-54f6-4dc2-e4e6-91a9f0b42489"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject11_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject12_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject10_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject02_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject18_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject16_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject19_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject17_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject21_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject23_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject26_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject22_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject25_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject24_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject32_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject30_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject33_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject27_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject28_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject29_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject07_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject34_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject08_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject04_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject06_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject09_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject01_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject35_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject05_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject20_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject03_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject15_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject14_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject00_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject13_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n","Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/DSP/MAT_dataset/during_MAT/Subject31_2.edf...\n","EDF file detected\n","Setting channel info structure...\n","Creating raw.info structure...\n","Reading 0 ... 30999  =      0.000 ...    61.998 secs...\n"]}]},{"cell_type":"markdown","source":["Slope Entropy\n"],"metadata":{"id":"LpmSX-LcPpr0"}},{"cell_type":"code","source":["!pip uninstall pandas\n","!pip install pandas --upgrade\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"peuVsQXqRyW3","executionInfo":{"status":"ok","timestamp":1729618260512,"user_tz":-330,"elapsed":26750,"user":{"displayName":"aditya","userId":"15779203425089853693"}},"outputId":"f85ad016-2b72-4038-e9fe-8e6fb6a426c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: pandas 2.2.2\n","Uninstalling pandas-2.2.2:\n","  Would remove:\n","    /usr/local/lib/python3.10/dist-packages/pandas-2.2.2.dist-info/*\n","    /usr/local/lib/python3.10/dist-packages/pandas/*\n","Proceed (Y/n)? y\n","  Successfully uninstalled pandas-2.2.2\n","Collecting pandas\n","  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pandas\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pandas-2.2.3\n"]}]},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","from scipy.stats import entropy\n","\n","def calculate_slope_entropy(signal, m=2, r=0.2):\n","    \"\"\"\n","    Calculate Slope Entropy of a given signal.\n","\n","    Args:\n","        signal (ndarray): 1D array of EEG/ECG signal.\n","        m (int): Embedding dimension.\n","        r (float): Threshold for similarity.\n","\n","    Returns:\n","        float: Slope Entropy value.\n","    \"\"\"\n","    n = len(signal)\n","    slopes = []\n","\n","    for i in range(n - m):\n","        # Create segments and calculate slope between them\n","        seg = signal[i:i+m]\n","        slope = (seg[-1] - seg[0]) / m  # Simple slope calculation\n","        slopes.append(slope)\n","\n","    # Bin the slopes into discrete values (use histogram binning)\n","    slope_bins, _ = np.histogram(slopes, bins='auto', density=True)\n","\n","    # Calculate Slope Entropy using Shannon entropy on the binned slopes\n","    slope_entropy_value = entropy(slope_bins + np.finfo(float).eps)  # Add epsilon to avoid log(0)\n","\n","    return slope_entropy_value\n","\n","def process_edf_files_for_slope_entropy(edf_folder, output_csv):\n","    \"\"\"\n","    Process all EDF files in a folder, compute Slope Entropy for each channel,\n","    and store results in a CSV file.\n","\n","    Args:\n","        edf_folder (str): Path to the folder containing EDF files.\n","        output_csv (str): Path to the output CSV file.\n","    \"\"\"\n","    # Initialize an empty DataFrame to store Slope Entropy results\n","    all_slope_entropy = pd.DataFrame()\n","\n","    # Loop through each EDF file in the folder\n","    for file_name in os.listdir(edf_folder):\n","        if file_name.endswith('.edf'):\n","            file_path = os.path.join(edf_folder, file_name)\n","\n","            # Read the EDF file using MNE\n","            raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n","            data, _ = raw[:, :]  # Get data from all channels\n","            sfreq = raw.info['sfreq']  # Sampling frequency\n","            ch_names = raw.info['ch_names']  # Channel names\n","\n","            # Dictionary to store Slope Entropy for each channel\n","            slope_entropy_values = {}\n","\n","            # Loop through each channel and calculate Slope Entropy\n","            for i, ch_name in enumerate(ch_names):\n","                channel_data = data[i, :]  # Get data for this channel\n","                slope_entropy = calculate_slope_entropy(channel_data)\n","                slope_entropy_values[ch_name] = slope_entropy\n","\n","            # Convert the slope entropy values to a DataFrame (single row)\n","            slope_entropy_df = pd.DataFrame(slope_entropy_values, index=[file_name])\n","\n","            # Append the result for this file to the main DataFrame\n","            all_slope_entropy = pd.concat([all_slope_entropy, slope_entropy_df])\n","\n","    # Save the results to a CSV file\n","    all_slope_entropy.to_csv(output_csv, index=True)\n","\n","# Example usage:\n","edf_folder_path = '/content/drive/MyDrive/Colab Notebooks/SamsungLabProjects/EEG_MAT/MAT_dataset/during_MAT'  # Replace with actual folder path\n","output_csv_path = '/content/drive/MyDrive/Colab Notebooks/SamsungLabProjects/EEG_MAT/MAT_dataset/extracted_features/during/slope_entropy_all_files.csv'\n","\n","# Process EDF files and compute Slope Entropy\n","process_edf_files_for_slope_entropy(edf_folder_path, output_csv_path)\n"],"metadata":{"id":"YaBc8k3LPVQD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dispersion entropy\n"],"metadata":{"id":"FRPFakn9VpKb"}},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","from scipy.stats import entropy\n","\n","def dispersion_entropy(signal, m=3, c=6, tau=1):\n","    \"\"\"\n","    Calculate Dispersion Entropy of a given signal.\n","\n","    Args:\n","        signal (ndarray): 1D array of EEG signal.\n","        m (int): Embedding dimension (default=3).\n","        c (int): Number of classes (bins) for data discretization (default=6).\n","        tau (int): Time delay (default=1).\n","\n","    Returns:\n","        float: Dispersion Entropy value.\n","    \"\"\"\n","    N = len(signal)\n","\n","    # Step 1: Normalize the signal to the range [0, 1]\n","    signal_min, signal_max = np.min(signal), np.max(signal)\n","    norm_signal = (signal - signal_min) / (signal_max - signal_min)\n","\n","    # Step 2: Discretize the normalized signal into 'c' bins (symbolization)\n","    discrete_signal = np.digitize(norm_signal, np.linspace(0, 1, c+1)) - 1\n","\n","    # Step 3: Form embedded matrix (embedding dimension: m, time delay: tau)\n","    embedded_matrix = np.array([discrete_signal[i:i + m * tau:tau] for i in range(N - (m - 1) * tau)])\n","\n","    # Step 4: Count the frequency of unique patterns\n","    unique_patterns, counts = np.unique(embedded_matrix, axis=0, return_counts=True)\n","\n","    # Step 5: Calculate probabilities and entropy\n","    probabilities = counts / counts.sum()\n","    dispen_value = entropy(probabilities)\n","\n","    return dispen_value\n","\n","def process_edf_files_for_dispersion_entropy(edf_folder, output_csv):\n","    \"\"\"\n","    Process all EDF files in a folder, compute Dispersion Entropy for each channel,\n","    and store results in a CSV file.\n","\n","    Args:\n","        edf_folder (str): Path to the folder containing EDF files.\n","        output_csv (str): Path to the output CSV file.\n","    \"\"\"\n","    # Initialize an empty DataFrame to store Dispersion Entropy results\n","    all_disp_en = pd.DataFrame()\n","\n","    # Loop through each EDF file in the folder\n","    for file_name in os.listdir(edf_folder):\n","        if file_name.endswith('.edf'):\n","            file_path = os.path.join(edf_folder, file_name)\n","\n","            # Read the EDF file using MNE\n","            raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n","            data, _ = raw[:, :]  # Get data from all channels\n","            sfreq = raw.info['sfreq']  # Sampling frequency\n","            ch_names = raw.info['ch_names']  # Channel names\n","\n","            # Dictionary to store Dispersion Entropy for each channel\n","            disp_en_values = {}\n","\n","            # Loop through each channel and calculate Dispersion Entropy\n","            for i, ch_name in enumerate(ch_names):\n","                channel_data = data[i, :]  # Get data for this channel\n","                disp_en = dispersion_entropy(channel_data)\n","                disp_en_values[ch_name] = disp_en\n","\n","            # Convert the Dispersion Entropy values to a DataFrame (single row)\n","            disp_en_df = pd.DataFrame(disp_en_values, index=[file_name])\n","\n","            # Append the result for this file to the main DataFrame\n","            all_disp_en = pd.concat([all_disp_en, disp_en_df])\n","\n","    # Save the results to a CSV file\n","    all_disp_en.to_csv(output_csv, index=True)\n","\n","# Example usage:\n","edf_folder_path = 'path_to_your_edf_folder'  # Replace with actual folder path\n","output_csv_path = 'dispersion_entropy_all_files.csv'\n","\n","# Process EDF files and compute Dispersion Entropy\n","process_edf_files_for_dispersion_entropy(edf_folder_path, output_csv_path)\n"],"metadata":{"id":"h_CM1cEqVv8i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Permutation entropy"],"metadata":{"id":"c-OWazK1V0CN"}},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","from scipy.stats import entropy\n","from itertools import permutations\n","\n","def permutation_entropy(signal, m=3, tau=1):\n","    \"\"\"\n","    Calculate Permutation Entropy of a given signal.\n","\n","    Args:\n","        signal (ndarray): 1D array of EEG signal.\n","        m (int): Embedding dimension (default=3).\n","        tau (int): Time delay (default=1).\n","\n","    Returns:\n","        float: Permutation Entropy value.\n","    \"\"\"\n","    n = len(signal)\n","\n","    # Step 1: Create embedded matrix with embedding dimension m and delay tau\n","    embedded_matrix = np.array([signal[i:i + m * tau:tau] for i in range(n - (m - 1) * tau)])\n","\n","    # Step 2: Create list of ordinal patterns for each embedded vector\n","    ordinal_patterns = [tuple(np.argsort(embedded_matrix[i])) for i in range(len(embedded_matrix))]\n","\n","    # Step 3: Count frequencies of each ordinal pattern\n","    unique_patterns, counts = np.unique(ordinal_patterns, axis=0, return_counts=True)\n","\n","    # Step 4: Calculate probabilities and Shannon entropy\n","    probabilities = counts / counts.sum()\n","    perm_en_value = entropy(probabilities)\n","\n","    return perm_en_value\n","\n","def process_edf_files_for_permutation_entropy(edf_folder, output_csv):\n","    \"\"\"\n","    Process all EDF files in a folder, compute Permutation Entropy for each channel,\n","    and store results in a CSV file.\n","\n","    Args:\n","        edf_folder (str): Path to the folder containing EDF files.\n","        output_csv (str): Path to the output CSV file.\n","    \"\"\"\n","    # Initialize an empty DataFrame to store Permutation Entropy results\n","    all_perm_en = pd.DataFrame()\n","\n","    # Loop through each EDF file in the folder\n","    for file_name in os.listdir(edf_folder):\n","        if file_name.endswith('.edf'):\n","            file_path = os.path.join(edf_folder, file_name)\n","\n","            # Read the EDF file using MNE\n","            raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n","            data, _ = raw[:, :]  # Get data from all channels\n","            sfreq = raw.info['sfreq']  # Sampling frequency\n","            ch_names = raw.info['ch_names']  # Channel names\n","\n","            # Dictionary to store Permutation Entropy for each channel\n","            perm_en_values = {}\n","\n","            # Loop through each channel and calculate Permutation Entropy\n","            for i, ch_name in enumerate(ch_names):\n","                channel_data = data[i, :]  # Get data for this channel\n","                perm_en = permutation_entropy(channel_data)\n","                perm_en_values[ch_name] = perm_en\n","\n","            # Convert the Permutation Entropy values to a DataFrame (single row)\n","            perm_en_df = pd.DataFrame(perm_en_values, index=[file_name])\n","\n","            # Append the result for this file to the main DataFrame\n","            all_perm_en = pd.concat([all_perm_en, perm_en_df])\n","\n","    # Save the results to a CSV file\n","    all_perm_en.to_csv(output_csv, index=True)\n","\n","# Example usage:\n","edf_folder_path = '/content/drive/MyDrive/Colab Notebooks/SamsungLabProjects/EEG_MAT/MAT_dataset/during_MAT'  # Replace with actual folder path\n","output_csv_path = '/content/drive/MyDrive/Colab Notebooks/SamsungLabProjects/EEG_MAT/MAT_dataset/extracted_features/during/permutation_entropy_all_files.csv'\n","\n","# Process EDF files and compute Permutation Entropy\n","process_edf_files_for_permutation_entropy(edf_folder_path, output_csv_path)\n"],"metadata":{"id":"cJ3SXWBjV2-8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["approximation entropy"],"metadata":{"id":"Ef2ZKxmhXojv"}},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","def approximate_entropy(U, m=2, r=0.2):\n","    \"\"\"\n","    Calculate Approximate Entropy (ApEn) of a given signal.\n","\n","    Args:\n","        U (ndarray): 1D array of EEG signal.\n","        m (int): Embedding dimension (default=2).\n","        r (float): Tolerance for accepting matches (default=0.2).\n","\n","    Returns:\n","        float: Approximate Entropy value.\n","    \"\"\"\n","    def _phi(m):\n","        \"\"\"Auxiliary function to calculate phi for given embedding dimension.\"\"\"\n","        x = np.array([U[i:i + m] for i in range(len(U) - m + 1)])\n","        C = np.sum(np.abs(x[:, np.newaxis] - x[np.newaxis, :]).max(axis=2) <= r, axis=0) / (len(U) - m + 1)\n","        return np.sum(np.log(C)) / (len(U) - m + 1)\n","\n","    return _phi(m) - _phi(m + 1)\n","\n","def process_edf_files_for_approximate_entropy(edf_folder, output_csv):\n","    \"\"\"\n","    Process all EDF files in a folder, compute Approximate Entropy for each channel,\n","    and store results in a CSV file.\n","\n","    Args:\n","        edf_folder (str): Path to the folder containing EDF files.\n","        output_csv (str): Path to the output CSV file.\n","    \"\"\"\n","    # Initialize an empty DataFrame to store Approximate Entropy results\n","    all_ap_en = pd.DataFrame()\n","\n","    # Loop through each EDF file in the folder\n","    for file_name in os.listdir(edf_folder):\n","        if file_name.endswith('.edf'):\n","            file_path = os.path.join(edf_folder, file_name)\n","\n","            # Read the EDF file using MNE\n","            raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n","            data, _ = raw[:, :]  # Get data from all channels\n","            sfreq = raw.info['sfreq']  # Sampling frequency\n","            ch_names = raw.info['ch_names']  # Channel names\n","\n","            # Dictionary to store Approximate Entropy for each channel\n","            ap_en_values = {}\n","\n","            # Loop through each channel and calculate Approximate Entropy\n","            for i, ch_name in enumerate(ch_names):\n","                channel_data = data[i, :]  # Get data for this channel\n","                ap_en = approximate_entropy(channel_data)\n","                ap_en_values[ch_name] = ap_en\n","\n","            # Convert the Approximate Entropy values to a DataFrame (single row)\n","            ap_en_df = pd.DataFrame(ap_en_values, index=[file_name])\n","\n","            # Append the result for this file to the main DataFrame\n","            all_ap_en = pd.concat([all_ap_en, ap_en_df])\n","\n","    # Save the results to a CSV file\n","    all_ap_en.to_csv(output_csv, index=True)\n","\n","# Example usage:\n","edf_folder_path = '/content/drive/MyDrive/Colab Notebooks/SamsungLabProjects/EEG_MAT/MAT_dataset/before_MAT'  # Replace with actual folder path\n","output_csv_path = '/content/drive/MyDrive/Colab Notebooks/SamsungLabProjects/EEG_MAT/MAT_dataset/extracted_features/before/approximate_entropy_all_files.csv'\n","\n","# Process EDF files and compute Approximate Entropy\n","process_edf_files_for_approximate_entropy(edf_folder_path, output_csv_path)\n"],"metadata":{"id":"tOniJZX4V3mF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Shanon Entropy"],"metadata":{"id":"NyEzqb8bZRo8"}},{"cell_type":"code","source":["import mne\n","import numpy as np\n","import pandas as pd\n","import os\n","from scipy.stats import entropy\n","\n","def shannon_entropy(signal, bins=100):\n","    \"\"\"\n","    Calculate Shannon Entropy of a given signal.\n","\n","    Args:\n","        signal (ndarray): 1D array of EEG signal.\n","        bins (int): Number of bins to use for estimating the probability distribution (default=100).\n","\n","    Returns:\n","        float: Shannon Entropy value.\n","    \"\"\"\n","    # Compute histogram of signal to estimate probability distribution\n","    histogram, bin_edges = np.histogram(signal, bins=bins, density=True)\n","    probabilities = histogram / histogram.sum()\n","\n","    # Filter out zero probabilities to avoid log(0)\n","    probabilities = probabilities[probabilities > 0]\n","\n","    # Calculate Shannon Entropy\n","    shannon_ent = entropy(probabilities)\n","    return shannon_ent\n","\n","def process_edf_files_for_shannon_entropy(edf_folder, output_csv):\n","    \"\"\"\n","    Process all EDF files in a folder, compute Shannon Entropy for each channel,\n","    and store results in a CSV file.\n","\n","    Args:\n","        edf_folder (str): Path to the folder containing EDF files.\n","        output_csv (str): Path to the output CSV file.\n","    \"\"\"\n","    # Initialize an empty DataFrame to store Shannon Entropy results\n","    all_shannon_ent = pd.DataFrame()\n","\n","    # Loop through each EDF file in the folder\n","    for file_name in os.listdir(edf_folder):\n","        if file_name.endswith('.edf'):\n","            file_path = os.path.join(edf_folder, file_name)\n","\n","            # Read the EDF file using MNE\n","            raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n","            data, _ = raw[:, :]  # Get data from all channels\n","            ch_names = raw.info['ch_names']  # Channel names\n","\n","            # Dictionary to store Shannon Entropy for each channel\n","            shannon_ent_values = {}\n","\n","            # Loop through each channel and calculate Shannon Entropy\n","            for i, ch_name in enumerate(ch_names):\n","                channel_data = data[i, :]  # Get data for this channel\n","                shannon_ent = shannon_entropy(channel_data)\n","                shannon_ent_values[ch_name] = shannon_ent\n","\n","            # Convert the Shannon Entropy values to a DataFrame (single row)\n","            shannon_ent_df = pd.DataFrame(shannon_ent_values, index=[file_name])\n","\n","            # Append the result for this file to the main DataFrame\n","            all_shannon_ent = pd.concat([all_shannon_ent, shannon_ent_df])\n","\n","    # Save the results to a CSV file\n","    all_shannon_ent.to_csv(output_csv, index=True)\n","\n","# Example usage:\n","edf_folder_path = '/content/drive/MyDrive/Colab Notebooks/SamsungLabProjects/EEG_MAT/MAT_dataset/during_MAT'  # Replace with actual folder path\n","output_csv_path = '/content/drive/MyDrive/Colab Notebooks/SamsungLabProjects/EEG_MAT/MAT_dataset/extracted_features/during/shannon_entropy_all_files.csv'\n","\n","# Process EDF files and compute Shannon Entropy\n","process_edf_files_for_shannon_entropy(edf_folder_path, output_csv_path)\n"],"metadata":{"id":"uPijLVlSZPCj"},"execution_count":null,"outputs":[]}]}